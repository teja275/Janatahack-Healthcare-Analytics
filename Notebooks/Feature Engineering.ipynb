{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas.api.types as ptypes\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import math, os, shutil, datetime\n",
    "import sqlite3\n",
    "warnings.filterwarnings('ignore')\n",
    "mpl.rcParams['figure.dpi'] = 500\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, auc, plot_confusion_matrix, plot_roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../Data/Train/Train.csv')\n",
    "firstcamp_data = pd.read_csv('../Data/Train/First_Health_Camp_Attended.csv')\n",
    "secondcamp_data = pd.read_csv('../Data/Train/Second_Health_Camp_Attended.csv')\n",
    "thirdcamp_data = pd.read_csv('../Data/Train/Third_Health_Camp_Attended.csv')\n",
    "healthcamp_data = pd.read_csv('../Data/Train/Health_Camp_Detail.csv')\n",
    "patient_data = pd.read_csv('../Data/Train/Patient_Profile.csv')\n",
    "\n",
    "test_data = pd.read_csv('../Data/test_l0Auv8Q.csv')\n",
    "submission_data = pd.read_csv('../Data/sample_submmission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final_data = pd.merge(train_data, firstcamp_data.drop('Unnamed: 4', axis=1), how='left', on=['Patient_ID', 'Health_Camp_ID'], indicator='camp1_merge_ind')\n",
    "train_final_data = pd.merge(train_final_data, secondcamp_data, how='left', on=['Patient_ID', 'Health_Camp_ID'], indicator='camp2_merge_ind')\n",
    "train_final_data = pd.merge(train_final_data, thirdcamp_data, how='left', on=['Patient_ID', 'Health_Camp_ID'], indicator='camp3_merge_ind')\n",
    "train_final_data = pd.merge(train_final_data, healthcamp_data, how='left', on='Health_Camp_ID', indicator='healthcamp_merge_ind')\n",
    "train_final_data = pd.merge(train_final_data, patient_data, how='left', on='Patient_ID', indicator='patient_merge_ind')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final_data['Outcome'] = 0\n",
    "train_final_data.loc[(train_final_data['camp1_merge_ind']=='both') | \n",
    "                     (train_final_data['camp2_merge_ind']=='both') |\n",
    "                     ((train_final_data['camp3_merge_ind']=='both') & (train_final_data['Number_of_stall_visited']>0))\n",
    "                     ,'Outcome'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final_data = pd.merge(test_data, firstcamp_data.drop('Unnamed: 4', axis=1), how='left', on=['Patient_ID', 'Health_Camp_ID'], indicator='camp1_merge_ind')\n",
    "test_final_data = pd.merge(test_final_data, secondcamp_data, how='left', on=['Patient_ID', 'Health_Camp_ID'], indicator='camp2_merge_ind')\n",
    "test_final_data = pd.merge(test_final_data, thirdcamp_data, how='left', on=['Patient_ID', 'Health_Camp_ID'], indicator='camp3_merge_ind')\n",
    "test_final_data = pd.merge(test_final_data, healthcamp_data, how='left', on='Health_Camp_ID', indicator='healthcamp_merge_ind')\n",
    "test_final_data = pd.merge(test_final_data, patient_data, how='left', on='Patient_ID', indicator='patient_merge_ind')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_cols = ['Registration_Date', 'Camp_Start_Date', 'Camp_End_Date', 'First_Interaction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_date(df):\n",
    "    for col in date_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_datetime(df[col], format='%d-%b-%y')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final_data = to_date(train_final_data)\n",
    "test_final_data = to_date(test_final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['Income', 'Education_Score', 'Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numeric(df, columns):\n",
    "    for col in df.columns:\n",
    "        if (col in num_cols) & ~(ptypes.is_numeric_dtype(df[col])):\n",
    "            df[col] = df[col].replace({'None':''})\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final_data = to_numeric(train_final_data, num_cols)\n",
    "test_final_data = to_numeric(test_final_data, num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Health_Camp_ID</th>\n",
       "      <th>Registration_Date</th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Donation</th>\n",
       "      <th>Health_Score</th>\n",
       "      <th>camp1_merge_ind</th>\n",
       "      <th>Health Score</th>\n",
       "      <th>camp2_merge_ind</th>\n",
       "      <th>Number_of_stall_visited</th>\n",
       "      <th>Last_Stall_Visited_Number</th>\n",
       "      <th>camp3_merge_ind</th>\n",
       "      <th>Camp_Start_Date</th>\n",
       "      <th>Camp_End_Date</th>\n",
       "      <th>Category1</th>\n",
       "      <th>Category2</th>\n",
       "      <th>Category3</th>\n",
       "      <th>healthcamp_merge_ind</th>\n",
       "      <th>Online_Follower</th>\n",
       "      <th>LinkedIn_Shared</th>\n",
       "      <th>Twitter_Shared</th>\n",
       "      <th>Facebook_Shared</th>\n",
       "      <th>Income</th>\n",
       "      <th>Education_Score</th>\n",
       "      <th>Age</th>\n",
       "      <th>First_Interaction</th>\n",
       "      <th>City_Type</th>\n",
       "      <th>Employer_Category</th>\n",
       "      <th>patient_merge_ind</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69348</th>\n",
       "      <td>485679</td>\n",
       "      <td>6578</td>\n",
       "      <td>2005-08-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>both</td>\n",
       "      <td>2005-08-16</td>\n",
       "      <td>2005-10-14</td>\n",
       "      <td>Third</td>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>both</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2005-08-12</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>both</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64479</th>\n",
       "      <td>485679</td>\n",
       "      <td>6555</td>\n",
       "      <td>2005-08-31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "      <td>2005-09-15</td>\n",
       "      <td>2005-09-19</td>\n",
       "      <td>Second</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>both</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2005-08-12</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>both</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6484</th>\n",
       "      <td>485680</td>\n",
       "      <td>6543</td>\n",
       "      <td>2006-07-10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "      <td>2005-09-27</td>\n",
       "      <td>2007-11-07</td>\n",
       "      <td>First</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>both</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006-07-10</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>both</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18999</th>\n",
       "      <td>485681</td>\n",
       "      <td>6580</td>\n",
       "      <td>2004-12-20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "      <td>2004-12-22</td>\n",
       "      <td>2005-01-06</td>\n",
       "      <td>First</td>\n",
       "      <td>E</td>\n",
       "      <td>2</td>\n",
       "      <td>both</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2004-12-19</td>\n",
       "      <td>G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>both</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2604</th>\n",
       "      <td>485681</td>\n",
       "      <td>6526</td>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "      <td>2005-01-03</td>\n",
       "      <td>2005-02-20</td>\n",
       "      <td>First</td>\n",
       "      <td>E</td>\n",
       "      <td>2</td>\n",
       "      <td>both</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2004-12-19</td>\n",
       "      <td>G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>both</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18124</th>\n",
       "      <td>528657</td>\n",
       "      <td>6531</td>\n",
       "      <td>2004-12-11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.670886</td>\n",
       "      <td>both</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "      <td>2004-12-09</td>\n",
       "      <td>2004-12-14</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>both</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004-10-25</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>both</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32744</th>\n",
       "      <td>528657</td>\n",
       "      <td>6580</td>\n",
       "      <td>2004-12-18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "      <td>2004-12-22</td>\n",
       "      <td>2005-01-06</td>\n",
       "      <td>First</td>\n",
       "      <td>E</td>\n",
       "      <td>2</td>\n",
       "      <td>both</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004-10-25</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>both</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7632</th>\n",
       "      <td>528657</td>\n",
       "      <td>6526</td>\n",
       "      <td>2004-12-30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "      <td>2005-01-03</td>\n",
       "      <td>2005-02-20</td>\n",
       "      <td>First</td>\n",
       "      <td>E</td>\n",
       "      <td>2</td>\n",
       "      <td>both</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004-10-25</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>both</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24471</th>\n",
       "      <td>528657</td>\n",
       "      <td>6536</td>\n",
       "      <td>2005-02-13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "      <td>0.102063</td>\n",
       "      <td>both</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "      <td>2005-02-15</td>\n",
       "      <td>2005-02-18</td>\n",
       "      <td>Second</td>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>both</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004-10-25</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>both</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3369</th>\n",
       "      <td>528657</td>\n",
       "      <td>6555</td>\n",
       "      <td>2005-09-16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "      <td>2005-09-15</td>\n",
       "      <td>2005-09-19</td>\n",
       "      <td>Second</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>both</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004-10-25</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>both</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75278 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Patient_ID  Health_Camp_ID Registration_Date  Var1  Var2  Var3  Var4  \\\n",
       "69348      485679            6578        2005-08-22     0     0     0     0   \n",
       "64479      485679            6555        2005-08-31     0     0     0     0   \n",
       "6484       485680            6543        2006-07-10     0     0     0     0   \n",
       "18999      485681            6580        2004-12-20     0     0     0     0   \n",
       "2604       485681            6526        2005-01-01     0     0     0     0   \n",
       "...           ...             ...               ...   ...   ...   ...   ...   \n",
       "18124      528657            6531        2004-12-11     0     0     0     0   \n",
       "32744      528657            6580        2004-12-18     0     0     0     0   \n",
       "7632       528657            6526        2004-12-30     0     0     0     0   \n",
       "24471      528657            6536        2005-02-13     0     0     0     0   \n",
       "3369       528657            6555        2005-09-16     0     0     0     0   \n",
       "\n",
       "       Var5  Donation  Health_Score camp1_merge_ind  Health Score  \\\n",
       "69348     0       NaN           NaN       left_only           NaN   \n",
       "64479     0       NaN           NaN       left_only           NaN   \n",
       "6484      0       NaN           NaN       left_only           NaN   \n",
       "18999     0       NaN           NaN       left_only           NaN   \n",
       "2604      0       NaN           NaN       left_only           NaN   \n",
       "...     ...       ...           ...             ...           ...   \n",
       "18124     0      20.0      0.670886            both           NaN   \n",
       "32744     0       NaN           NaN       left_only           NaN   \n",
       "7632      0       NaN           NaN       left_only           NaN   \n",
       "24471     0       NaN           NaN       left_only      0.102063   \n",
       "3369      0       NaN           NaN       left_only           NaN   \n",
       "\n",
       "      camp2_merge_ind  Number_of_stall_visited  Last_Stall_Visited_Number  \\\n",
       "69348       left_only                      4.0                        4.0   \n",
       "64479       left_only                      NaN                        NaN   \n",
       "6484        left_only                      NaN                        NaN   \n",
       "18999       left_only                      NaN                        NaN   \n",
       "2604        left_only                      NaN                        NaN   \n",
       "...               ...                      ...                        ...   \n",
       "18124       left_only                      NaN                        NaN   \n",
       "32744       left_only                      NaN                        NaN   \n",
       "7632        left_only                      NaN                        NaN   \n",
       "24471            both                      NaN                        NaN   \n",
       "3369        left_only                      NaN                        NaN   \n",
       "\n",
       "      camp3_merge_ind Camp_Start_Date Camp_End_Date Category1 Category2  \\\n",
       "69348            both      2005-08-16    2005-10-14     Third         G   \n",
       "64479       left_only      2005-09-15    2005-09-19    Second         A   \n",
       "6484        left_only      2005-09-27    2007-11-07     First         F   \n",
       "18999       left_only      2004-12-22    2005-01-06     First         E   \n",
       "2604        left_only      2005-01-03    2005-02-20     First         E   \n",
       "...               ...             ...           ...       ...       ...   \n",
       "18124       left_only      2004-12-09    2004-12-14     First         C   \n",
       "32744       left_only      2004-12-22    2005-01-06     First         E   \n",
       "7632        left_only      2005-01-03    2005-02-20     First         E   \n",
       "24471       left_only      2005-02-15    2005-02-18    Second         D   \n",
       "3369        left_only      2005-09-15    2005-09-19    Second         A   \n",
       "\n",
       "       Category3 healthcamp_merge_ind  Online_Follower  LinkedIn_Shared  \\\n",
       "69348          2                 both                0                0   \n",
       "64479          2                 both                0                0   \n",
       "6484           2                 both                0                0   \n",
       "18999          2                 both                0                0   \n",
       "2604           2                 both                0                0   \n",
       "...          ...                  ...              ...              ...   \n",
       "18124          2                 both                0                0   \n",
       "32744          2                 both                0                0   \n",
       "7632           2                 both                0                0   \n",
       "24471          2                 both                0                0   \n",
       "3369           2                 both                0                0   \n",
       "\n",
       "       Twitter_Shared  Facebook_Shared  Income  Education_Score   Age  \\\n",
       "69348               0                0     NaN              NaN   NaN   \n",
       "64479               0                0     NaN              NaN   NaN   \n",
       "6484                0                0     NaN              NaN   NaN   \n",
       "18999               0                1     0.0              NaN  46.0   \n",
       "2604                0                1     0.0              NaN  46.0   \n",
       "...               ...              ...     ...              ...   ...   \n",
       "18124               0                0     NaN              NaN   NaN   \n",
       "32744               0                0     NaN              NaN   NaN   \n",
       "7632                0                0     NaN              NaN   NaN   \n",
       "24471               0                0     NaN              NaN   NaN   \n",
       "3369                0                0     NaN              NaN   NaN   \n",
       "\n",
       "      First_Interaction City_Type Employer_Category patient_merge_ind  Outcome  \n",
       "69348        2005-08-12         I               NaN              both        1  \n",
       "64479        2005-08-12         I               NaN              both        0  \n",
       "6484         2006-07-10         A               NaN              both        0  \n",
       "18999        2004-12-19         G               NaN              both        0  \n",
       "2604         2004-12-19         G               NaN              both        0  \n",
       "...                 ...       ...               ...               ...      ...  \n",
       "18124        2004-10-25         D               NaN              both        1  \n",
       "32744        2004-10-25         D               NaN              both        0  \n",
       "7632         2004-10-25         D               NaN              both        0  \n",
       "24471        2004-10-25         D               NaN              both        1  \n",
       "3369         2004-10-25         D               NaN              both        0  \n",
       "\n",
       "[75278 rows x 34 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_final_data.sort_values(['Patient_ID','Registration_Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unnec_cols = ['camp1_merge_ind', 'camp2_merge_ind', 'camp3_merge_ind', 'healthcamp_merge_ind', 'patient_merge_ind']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final_data = train_final_data.drop(unnec_cols, axis=1)\n",
    "test_final_data = test_final_data.drop(unnec_cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Imputations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_impute_cols = ['Age']\n",
    "imp_mean = SimpleImputer(strategy='mean')\n",
    "imp_mean.fit(train_final_data[mean_impute_cols])\n",
    "train_final_data[mean_impute_cols] = imp_mean.transform(train_final_data[mean_impute_cols])\n",
    "test_final_data[mean_impute_cols] = imp_mean.transform(test_final_data[mean_impute_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequent Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_impute_cols = ['Income', 'Education_Score', 'City_Type', 'Employer_Category']\n",
    "imp_freq = SimpleImputer(strategy='most_frequent')\n",
    "imp_freq.fit(train_final_data[freq_impute_cols])\n",
    "train_final_data[freq_impute_cols] = imp_freq.transform(train_final_data[freq_impute_cols])\n",
    "test_final_data[freq_impute_cols] = imp_freq.transform(test_final_data[freq_impute_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_impute_cols = ['Donation', 'Health_Score', 'Health Score', 'Number_of_stall_visited', 'Last_Stall_Visited_Number']\n",
    "train_final_data[zero_impute_cols] = train_final_data[zero_impute_cols].fillna(0)\n",
    "test_final_data[zero_impute_cols] = test_final_data[zero_impute_cols].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Date Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_impute(df):\n",
    "    midpoint = df['Camp_Start_Date'] + (df['Camp_End_Date'] - df['Camp_Start_Date'])/2\n",
    "    df['Registration_Date'] = df['Registration_Date'].fillna(midpoint)\n",
    "    df['Registration_Date'] = pd.to_datetime(df['Registration_Date'], format='%Y-%m-%d')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final_data = date_impute(train_final_data)\n",
    "test_final_data = date_impute(test_final_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Duration of camp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final_data['Camp Duration'] = (train_final_data['Camp_End_Date'] - train_final_data['Camp_Start_Date']).dt.days\n",
    "test_final_data['Camp Duration'] = (test_final_data['Camp_End_Date'] - test_final_data['Camp_Start_Date']).dt.days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Registered before/after start of camp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final_data['reg_start_diff'] = (train_final_data['Camp_Start_Date'] - train_final_data['Registration_Date']).dt.days\n",
    "test_final_data['reg_start_diff'] = (test_final_data['Camp_Start_Date'] - test_final_data['Registration_Date']).dt.days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Days left for camp end?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final_data['days_for_camp_end'] = (train_final_data['Registration_Date'] - train_final_data['Camp_End_Date']).dt.days\n",
    "test_final_data['days_for_camp_end'] = (test_final_data['Registration_Date'] - test_final_data['Camp_End_Date']).dt.days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Point in camp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final_data['point_in_camp'] = 1- train_final_data['days_for_camp_end']/train_final_data['Camp Duration']\n",
    "test_final_data['point_in_camp'] = 1- test_final_data['days_for_camp_end']/test_final_data['Camp Duration']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Days since first and last interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final_data['is_train'] = True\n",
    "test_final_data['is_train'] = False\n",
    "all_data = pd.concat([train_final_data,test_final_data])\n",
    "all_data = all_data.reset_index(drop=True)\n",
    "all_data = all_data.sort_values(['Patient_ID', 'Registration_Date'])\n",
    "all_data = all_data.reset_index(drop=True)\n",
    "patient_wise_visits = all_data.loc[:,['Patient_ID','Registration_Date']]\n",
    "patient_wise_visits = patient_wise_visits.drop_duplicates()\n",
    "patient_wise_visits = patient_wise_visits.reset_index(drop=True)\n",
    "patient_wise_visits['Last_Interaction'] = patient_wise_visits.groupby('Patient_ID')['Registration_Date'].shift()\n",
    "all_data = pd.merge(all_data,patient_wise_visits,on=['Patient_ID', 'Registration_Date'],how='left')\n",
    "all_data.loc[all_data['Last_Interaction'].isna(),'Last_Interaction'] = all_data['First_Interaction']\n",
    "all_data['days_since_first_interaction'] = (all_data['Registration_Date'] - all_data['First_Interaction']).dt.days\n",
    "all_data['days_since_last_interaction'] = (all_data['Registration_Date'] - all_data['Last_Interaction']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = all_data.loc[:,['Patient_ID','Registration_Date', 'Donation', 'Number_of_stall_visited', 'Health_Camp_ID']]\n",
    "temp = temp.drop_duplicates()\n",
    "temp = temp.reset_index(drop=True)\n",
    "temp['Last Interaction'] = temp.groupby('Patient_ID')['Registration_Date'].shift()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[['Patient_ID','Registration_Date', 'Donation', 'Number_of_stall_visited', 'Health_Camp_ID','First_Interaction','Last_Interaction']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make the db in memory\n",
    "conn = sqlite3.connect(':memory:')\n",
    "#write the tables\n",
    "all_data.to_sql('all_data', conn, index=False)\n",
    "\n",
    "qry = '''\n",
    "        select a.Patient_ID, a.Registration_Date, sum(b.Donation) as total_donation,\n",
    "        avg(b.Donation) as avg_donation_per_camp,\n",
    "        count(b.Health_Camp_ID) as total_camps_till_now,\n",
    "        sum(b.Number_of_stall_visited) as total_stalls_till_now,\n",
    "        avg(b.Number_of_stall_visited) as avg_stalls_per_camp_till_now\n",
    "        from all_data as a left join all_data as b\n",
    "        on a.Patient_ID = b.Patient_ID\n",
    "        and b.Registration_Date < a.Registration_Date\n",
    "        group by a.Patient_ID, a.Registration_Date\n",
    "      '''\n",
    "check = pd.read_sql_query(qry, conn)\n",
    "check['Registration_Date'] = pd.to_datetime(check['Registration_Date'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check[check['Patient_ID']==485702]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['same_day_reg_count'] = all_data.groupby(['Registration_Date','Patient_ID'])['Health_Camp_ID'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[all_data['same_day_reg_count']>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.merge(check,all_data,on=['Patient_ID','Registration_Date'],how='outer',indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp._merge.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[all_data['Patient_ID']==485683]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check[check['Patient_ID']==485683]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check['avg_donation_till_now'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID1 = 'Patient_ID'\n",
    "ID2 = 'Health_Camp_ID'\n",
    "target = 'Outcome'\n",
    "date_columns = ['Registration_Date', 'Camp_Start_Date', 'Camp_End_Date', 'First_Interaction']\n",
    "discrete_columns = ['Var1', 'Var2', 'Var3', 'Var4', 'Var5', 'Category1', 'Category2', 'Category3', 'Online_Follower', \n",
    "                   'LinkedIn_Shared', 'Twitter_Shared', 'Facebook_Shared', 'City_Type', 'Employer_Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "should_ohe = True\n",
    "should_scale = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if should_scale:\n",
    "    for col in train_final_data.columns:\n",
    "        if (col != target) and (col != ID1) and (col != ID2) and (col not in date_columns) and (col not in discrete_columns):\n",
    "            mms = MinMaxScaler()\n",
    "            ss = StandardScaler()\n",
    "            rs = RobustScaler()\n",
    "            pt = PowerTransformer()\n",
    "            ft_log = FunctionTransformer(np.log)\n",
    "            \n",
    "            train_final_data[f\"{col}_MMS\"] = mms.fit_transform(train_final_data[[col]])\n",
    "            test_final_data[f\"{col}_MMS\"] = mms.transform(test_final_data[[col]])\n",
    "            \n",
    "            train_final_data[f\"{col}_SS\"] = ss.fit_transform(train_final_data[[col]])\n",
    "            test_final_data[f\"{col}_SS\"] = ss.transform(test_final_data[[col]])\n",
    "            \n",
    "            train_final_data[f\"{col}_RS\"] = rs.fit_transform(train_final_data[[col]])\n",
    "            test_final_data[f\"{col}_RS\"] = rs.transform(test_final_data[[col]])\n",
    "            \n",
    "            train_final_data[f\"{col}_PT\"] = pt.fit_transform(train_final_data[[col]])\n",
    "            test_final_data[f\"{col}_PT\"] = pt.transform(test_final_data[[col]])\n",
    "            \n",
    "#             train_final_data[f\"{col}_FT_log\"] = ft_log.fit_transform(train_final_data[[col]])\n",
    "#             test_final_data[f\"{col}_FT_log\"] = ft_log.transform(test_final_data[[col]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final_data['is_train'] = True\n",
    "test_final_data['is_train'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_for_ohe = ['Category1', 'Category2', 'City_Type', 'Employer_Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final_data = pd.concat([train_final_data.drop(cols_for_ohe,axis=1),pd.get_dummies(train_final_data[cols_for_ohe])],axis=1)\n",
    "test_final_data = pd.concat([test_final_data.drop(cols_for_ohe,axis=1),pd.get_dummies(test_final_data[cols_for_ohe])],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_cols_train = [ID1, ID2, target, 'Registration_Date', 'Camp_Start_Date', 'Camp_End_Date', 'First_Interaction']\n",
    "ignore_cols_test = [ID1, ID2, 'Registration_Date', 'Camp_Start_Date', 'Camp_End_Date', 'First_Interaction']\n",
    "X, y = train_final_data.drop(ignore_cols_train, axis=1), train_final_data[target]\n",
    "X_test = test_final_data.drop(ignore_cols_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(X_test.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.30, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_esitmators = 1000\n",
    "classifiers = {\n",
    "    \"DT\": DecisionTreeClassifier(),\n",
    "    \"RF\": RandomForestClassifier(n_estimators=n_esitmators, random_state=random_state),\n",
    "    \"GBM\": GradientBoostingClassifier(n_estimators=n_esitmators, random_state=random_state),\n",
    "    \"GBM_ES\": GradientBoostingClassifier(n_estimators=n_esitmators, validation_fraction=0.2, \n",
    "                                         n_iter_no_change=5,tol=0.01,random_state=random_state)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_ct=0\n",
    "for model_name,clf in classifiers.items():\n",
    "    print(f\"{clf_ct+1} Building {model_name} starts..\")\n",
    "    start_ts = datetime.datetime.now()\n",
    "    \n",
    "    cv_scores = cross_val_score(clf, X_train, y_train, scoring='roc_auc', cv=5)\n",
    "    print(f\"\\t Mean ROC AUC: {np.mean(cv_scores)} +/- {np.std(cv_scores)}\")\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    predictions = clf.predict(X_val)\n",
    "    auc_score = roc_auc_score(y_val, predictions)\n",
    "    print(f\"\\t ROC AUC: {auc_score}\")\n",
    "    \n",
    "    fig = plt.figure(figsize=(12,7))\n",
    "    ax = fig.add_subplot(111)\n",
    "    disp = plot_confusion_matrix(clf, X_val, y_val, normalize='true', ax=ax, cmap=plt.cm.Blues)\n",
    "    disp.ax_.set_title(f\"Confustion Matrix for model: {model_name}\")\n",
    "    os.makedirs(\"../plots/confusion_matrix_scale_ohe\",exist_ok=True)\n",
    "    plt.savefig(f\"../plots/confusion_matrix_scale_ohe/{model_name}.png\", dpi=300)\n",
    "    end_ts = datetime.datetime.now()\n",
    "    \n",
    "    print(f\"It took {end_ts - start_ts} time to finish the modelling\")\n",
    "    print(f\"{clf_ct+1} Building {model_name} starts..\")\n",
    "    \n",
    "    clf_ct+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(train_final_data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_imp = pd.DataFrame({'var':X.columns, 'var_imp':classifiers['GBM'].feature_importances_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_imp.sort_values('var_imp', ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
